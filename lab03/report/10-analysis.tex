\section{Аналитический раздел}

\subsection{TF-IDF}

\textbf{TF-IDF} (Term Frequency-Inverse Document Frequency) -- это статистическая мера, используемая в информационном поиске и анализе текста для оценки важности слова в документе относительно всей коллекции документов. Эта мера может быть полезной и в рекомендательных системах для оценки сходства между элементами и пользователями. \cite{tfidf}

\textbf{TF} -- частота слова, отношение числа вхождений некоторого слова к общему числу слов документа, так оценивается важность слова $t_i$ в пределах отдельного документа:

\begin{equation}
	tf(t, d) = \frac{n_t}{\sum_{k}{n_k}},
\end{equation}
\eqexplSetIntro{где}
\begin{eqexpl}[15mm]
\item{$n_t$} число вхождений слова t в документ;
\item{$\sum_{k}{n_k}$} общее количество слов в данном документе.
\end{eqexpl}

\textbf{IDF} -- обратная частота документа, инверсия частоты, с которой некоторое слово встречается в документах коллекции.

\begin{equation}
	IDF(t, D) = log \frac{|D|}{|\{d_i \in D | t \in d_i\}|},
\end{equation}
\eqexplSetIntro{где}
\begin{eqexpl}[15mm]
\item{$|D|$} число документов в коллекции;
\item{$|\{d_i \in D | t \in d_i\}|$} число документов из коллекции $D$, в которых встречается $t$ (когда $n_t \neq 0$).
\end{eqexpl}

Данная мера может быть использована в рекомендательных системах для:

\begin{itemize}
	\item Представления контента, такого как текстовые описания товаров, фильмов или музыкальных треков; каждый объект (например, товар) будет представлен его описанием-вектором, в котором каждое слово представлено его TF-IDF весом, что позволит понимать, какие слова играют важную роль в этом описании -- выделить ``тэги'';
	\item Определения сходства элементов и пользователя через косинусное сходство между векторами; элементы, чьи векторы более похожи на вектор пользователя, могут быть ему рекомендованы;
	\item Улучшения рекомендаций путем подсчета весовых коэффициентов для слов или фраз в профилях пользователей; если пользователь часто взаимодействует с элементами, содержащими определенные ключевые слова, то можно увеличить вес для этих слов в профиле пользователя;
	\item Модификации; TF-IDF может быть использован вместе с другими методами рекомендации, например, с коллаборативной фильтрацией, для улучшения точности и разнообразия рекомендаций.
\end{itemize}

При этом TF-IDF имеет некоторые ограничения: он не учитывает контекст слов и не способен обрабатывать синонимы. \cite{tfidf}

\subsection{LDA}

\textbf{LDA} (Latent Dirichlet Allocation) -- это статистическая модель, используемая в анализе текстовых данных для выявления скрытых тем в коллекции документов. Данная модель предполагает, что каждый документ в коллекции создается путем комбинирования нескольких тем, и каждая тема представляет собой распределение слов. \cite{lda}

Данная модель может быть использована в рекомендательных системах для \cite{lda}:

\begin{itemize}
	\item Извлечения тематических профилей -- путем применения LDA к текстовым данным, можно извлечь тематические профили для каждого объекта, которые представляют собой вероятностные распределения тем в каждом элементе;
	\item Рекомендаций на основе тем -- при наличии профилей объекта и пользователя, можно измерить сходство между темами и рекомендовать объекты, которые имеют близкие тематические профили к профилю пользователя;
	\item Разнообразия рекомендаций -- LDA может помочь в улучшении разнообразия, так как модель позволяет контролировать количество тем;
	\item Персонализации -- модель может быть адаптирована к поведению конкретного пользователя, чтобы улучшить качество рекомендаций.
\end{itemize}

Преимущество LDA над TF-IDF заключается в том, что он учитывает более высокоуровневую структуру текстовых данных и может обнаруживать тематические зависимости между словами. Однако LDA имеет и ограничения: необходимость выбора количества тем (подбор значения данного параметра), и он может быть более сложным в реализации и настройке, чем TF-IDF.

\pagebreak