\section{Аналитический раздел}

\subsection{Матричная факторизация}
Матричная факторизация -- это класс алгоритмов коллаборативной фильтрации, используемых в рекомендательных системах. Данные алгоритмы работают путем разложения матрицы взаимодействия пользователя с объектами на произведение двух прямоугольных матриц меньшей размерности. Зачастую матричная факторизация используется для улучшения качества персонализированных рекомендаций, позволяя выявить скрытые паттерны и взаимосвязи между пользователями и товарами.\cite{factorization}

Методы матричной факторизации в рекомендательных системах обладают следующими аспектами:

\begin{itemize}
	\item Снижение размерности -- уменьшение объема вычислений и улучшение эффективности;
	\item Скрытые факторы -- данные методы предполагают, что в системе присутствуют некоторые латентные признаки, которые влияют на предпочтения пользователей и характеристики товаров;
	\item Эффективность работы с разреженными данными -- матричная факторизация может эффективно работать с разреженными данными, заполняя недостающие значения.
\end{itemize}

\subsection{Funk SVD}
\textbf{Funk SVD} -- это один из методов матричной факторизации, который был предложен Саймоном Функом и является одним из ранних подходов к коллаборативной фильтрации.

Целью обучения Funk SVD является минимизация разницы между фактическими оценками пользователей и предсказанными на основе разложения матрицы. Для оптимизации параметров разложения и нахождения оптимальных значений скрытых факторов используется градиентный спуск. \cite{svd}

Для оценки качества модели обычно используются среднеквадратичная ошибка (RMSE) и средняя абсолютная ошибка (MAE).

Funk SVD имеет также и свои ограничения -- он не способен учитывать неявные обратные связи и отсутствие возможности холодного старта.

Прогнозируемую оценку можно рассчитать как:

\begin{equation}
	\widetilde{R} = HW
\end{equation}
\eqexplSetIntro{где}
\begin{eqexpl}[35mm]
\item{$\widetilde{R} \in \mathbb{R}^{users \times items}$} матрица оценок пользователя;
\item{$H \in \mathbb{R}^{userx \times latent factors}$} содержит латентные признаки пользователя;
\item{$W \in \mathbb{R}^{latent factors \times items}$} скрытые признаки объекта.
\end{eqexpl}

В частности, прогнозируемая оценка пользователя $u$ объекту $i$:
\begin{equation}
	\widetilde{r}_{ui} = \sum^{n factors}_{f = 0} H_{u, f} W_{f, i}
\end{equation}

\subsection{SVD++}

SVD++ -- это усовершенствование SVD, которая было разработано для решения некоторых ограничений традиционных SVD-моделей. SVD++ учитывает не только явные оценки или взаимодействия пользователей с товарами, но и неявные взаимодействия. Кроме того, он также учитывает предвзятость пользователя к объекту.

Прогнозируемая оценка, которую пользователь $u$ поставит объекту $i$, рассчитывается как:

\begin{equation}
	\widetilde{r}_{ui} = \mu + b_i + b_u + \sum^{n factors}_{f = 0}{H_{u, f} W_{f, i}}
\end{equation}
\eqexplSetIntro{где}
\begin{eqexpl}[15mm]
\item{$\mu$} относится к общей средней оценке;
\item{$b_i, b_u$} относятся к наблюдаемому отклонению объекта $i$ и пользователя $u$ от среднего.
\end{eqexpl}

Главным недостатком SVD++ является то, что при добавлении нового пользователя требуется переобучение модели.

\pagebreak